{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load Data</a></span></li><li><span><a href=\"#Data-Preparation\" data-toc-modified-id=\"Data-Preparation-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data Preparation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Hillstrom\" data-toc-modified-id=\"Hillstrom-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Hillstrom</a></span></li><li><span><a href=\"#Mayo-PBC\" data-toc-modified-id=\"Mayo-PBC-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Mayo PBC</a></span></li><li><span><a href=\"#CMF-Microfinance\" data-toc-modified-id=\"CMF-Microfinance-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>CMF Microfinance</a></span></li></ul></li><li><span><a href=\"#Iterative-Modeling\" data-toc-modified-id=\"Iterative-Modeling-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Iterative Modeling</a></span></li><li><span><a href=\"#Evaluation-and-Variance-Table\" data-toc-modified-id=\"Evaluation-and-Variance-Table-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Evaluation and Variance Table</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterated analysis of all included models over all inlcuded datasets.\n",
    "\n",
    "If using this notebook in [Google Colab](https://colab.research.google.com/github/andrewtavis/causeinfer/blob/main/examples/model_iteration.ipynb), you can activate GPUs by following `Edit > Notebook settings > Hardware accelerator` and selecting `GPU`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T15:02:53.009494Z",
     "start_time": "2021-04-03T15:02:53.006855Z"
    }
   },
   "outputs": [],
   "source": [
    "# pip install causeinfer -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T15:02:54.305805Z",
     "start_time": "2021-04-03T15:02:53.203951Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:99% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "from causeinfer import utils\n",
    "from causeinfer.data import hillstrom, mayo_pbc, cmf_micro\n",
    "from causeinfer.standard_algorithms.two_model import TwoModel\n",
    "from causeinfer.standard_algorithms.interaction_term import InteractionTerm\n",
    "from causeinfer.standard_algorithms.binary_transformation import BinaryTransformation\n",
    "from causeinfer.standard_algorithms.quaternary_transformation import (\n",
    "    QuaternaryTransformation,\n",
    ")\n",
    "from causeinfer.standard_algorithms.reflective import ReflectiveUplift\n",
    "from causeinfer.standard_algorithms.pessimistic import PessimisticUplift\n",
    "from causeinfer.evaluation import qini_score, auuc_score\n",
    "from causeinfer.evaluation import plot_cum_effect, plot_cum_gain, plot_qini\n",
    "from causeinfer.evaluation import plot_batch_responses, signal_to_noise\n",
    "from causeinfer.evaluation import iterate_model, eval_table\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 16)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:99% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T15:02:55.269030Z",
     "start_time": "2021-04-03T15:02:55.266307Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset already exists at /Users/andrewtavis/Documents/learning/coding/causeinfer/examples/datasets/hillstrom.csv\n",
      "The dataset already exists at /Users/andrewtavis/Documents/learning/coding/causeinfer/examples/datasets/mayo_pbc.text\n"
     ]
    }
   ],
   "source": [
    "hillstrom.download_hillstrom()\n",
    "mayo_pbc.download_mayo_pbc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T15:04:22.230955Z",
     "start_time": "2021-04-03T15:04:21.318664Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewtavis/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "data_hillstrom = hillstrom.load_hillstrom(\n",
    "    file_path=\"datasets/hillstrom.csv\", format_covariates=True, normalize=True\n",
    ")\n",
    "data_mayo_pbc = mayo_pbc.load_mayo_pbc(\n",
    "    file_path=\"datasets/mayo_pbc.text\", format_covariates=True, normalize=True\n",
    ")\n",
    "data_cmf_micro = cmf_micro.load_cmf_micro(\n",
    "    file_path=\"datasets/cmf_micro\", format_covariates=True, normalize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hillstrom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T15:02:57.894953Z",
     "start_time": "2021-04-03T15:02:57.892597Z"
    }
   },
   "outputs": [],
   "source": [
    "# Covariates, treatments and responses are loaded separately\n",
    "X_hillstrom = data_hillstrom[\"features\"]\n",
    "\n",
    "y_hillstrom = data_hillstrom[\n",
    "    \"response_visit\"\n",
    "]  # response_visit, response_spend or response_conversion\n",
    "\n",
    "# 1 is men's campaign, 2 is women's, and 0 is control\n",
    "w_hillstrom = data_hillstrom[\"treatment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T15:02:58.824010Z",
     "start_time": "2021-04-03T15:02:58.767715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21306\n",
      "21307\n",
      "21387\n",
      "42694\n"
     ]
    }
   ],
   "source": [
    "# Counts for treatment\n",
    "control_indexes_hillstrom = [i for i, e in enumerate(w_hillstrom) if e == 0]\n",
    "mens_indexes = [i for i, e in enumerate(w_hillstrom) if e == 1]\n",
    "womens_indexes = [i for i, e in enumerate(w_hillstrom) if e == 2]\n",
    "\n",
    "womens_mens_indexes = womens_indexes + mens_indexes\n",
    "\n",
    "print(len(control_indexes_hillstrom))\n",
    "print(len(mens_indexes))\n",
    "print(len(womens_indexes))\n",
    "print(len(womens_mens_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T15:02:59.296096Z",
     "start_time": "2021-04-03T15:02:59.279408Z"
    }
   },
   "outputs": [],
   "source": [
    "X_control_hillstrom = X_hillstrom[control_indexes_hillstrom]\n",
    "y_control_hillstrom = y_hillstrom[control_indexes_hillstrom]\n",
    "w_control_hillstrom = w_hillstrom[control_indexes_hillstrom]\n",
    "\n",
    "X_women = X_hillstrom[womens_indexes]\n",
    "y_women = y_hillstrom[womens_indexes]\n",
    "w_women = w_hillstrom[womens_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T15:02:59.879571Z",
     "start_time": "2021-04-03T15:02:59.871047Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change 2s to 1s in women's campaign\n",
    "w_women = [1 for i in w_women if i == 2]\n",
    "w_women[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T15:03:00.581839Z",
     "start_time": "2021-04-03T15:03:00.563416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Old Covariates shape  : (21306, 18)\n",
      "    Old responses shape   : (21306,)\n",
      "    Old treatments shape  : (21306,)\n",
      "    New covariates shape  : (21387, 18)\n",
      "    New responses shape   : (21387,)\n",
      "    New treatments shape  : (21387,)\n",
      "    Matched sample length :  21387\n",
      "                        \n"
     ]
    }
   ],
   "source": [
    "# Over-sampling of control\n",
    "X_os_hillstrom, y_os_hillstrom, w_os_hillstrom = utils.over_sample(\n",
    "    X_1=X_control_hillstrom,\n",
    "    y_1=y_control_hillstrom,\n",
    "    w_1=w_control_hillstrom,\n",
    "    sample_2_size=len(X_women),\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T15:03:01.365170Z",
     "start_time": "2021-04-03T15:03:01.359180Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42774, 18), (42774,), (42774,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_split_hillstrom = np.append(X_os_hillstrom, X_women, axis=0)\n",
    "y_split_hillstrom = np.append(y_os_hillstrom, y_women, axis=0)\n",
    "w_split_hillstrom = np.append(w_os_hillstrom, w_women, axis=0)\n",
    "\n",
    "X_split_hillstrom.shape, y_split_hillstrom.shape, w_split_hillstrom.shape  # Should all be equal in the first dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T15:03:10.456400Z",
     "start_time": "2021-04-03T15:03:01.899482Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29940, 18), (12834, 18), (29940,), (12834,), (29940,), (12834,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    X_train_hillstrom,\n",
    "    X_test_hillstrom,\n",
    "    y_train_hillstrom,\n",
    "    y_test_hillstrom,\n",
    "    w_train_hillstrom,\n",
    "    w_test_hillstrom,\n",
    ") = utils.train_test_split(\n",
    "    X_split_hillstrom,\n",
    "    y_split_hillstrom,\n",
    "    w_split_hillstrom,\n",
    "    percent_train=0.7,\n",
    "    random_state=42,\n",
    "    maintain_proportions=True,\n",
    ")\n",
    "X_train_hillstrom.shape, X_test_hillstrom.shape, y_train_hillstrom.shape, y_test_hillstrom.shape, w_train_hillstrom.shape, w_test_hillstrom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T15:03:10.463334Z",
     "start_time": "2021-04-03T15:03:10.458783Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0 14970]\n",
      " [    1 14970]]\n",
      "[[   0 6417]\n",
      " [   1 6417]]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(np.unique(w_train_hillstrom, return_counts=True)).T)\n",
    "print(np.array(np.unique(w_test_hillstrom, return_counts=True)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mayo PBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T15:03:12.212257Z",
     "start_time": "2021-04-03T15:03:12.209393Z"
    }
   },
   "outputs": [],
   "source": [
    "# Covariates, treatments and responses are loaded separately\n",
    "X_mayo = data_mayo_pbc[\"features\"]\n",
    "\n",
    "# 0 is the patient is alive, 1 is a liver transplant, 2 is deceased\n",
    "y_mayo = data_mayo_pbc[\"response\"]\n",
    "\n",
    "w_mayo = data_mayo_pbc[\"treatment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T15:03:12.357248Z",
     "start_time": "2021-04-03T15:03:12.352321Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\n",
      "19\n",
      "125\n",
      "144\n"
     ]
    }
   ],
   "source": [
    "# Counts for response\n",
    "alive_indexes = [i for i, e in enumerate(y_mayo) if e == 0]\n",
    "transplant_indexes = [i for i, e in enumerate(y_mayo) if e == 1]\n",
    "deceased_indexes = [i for i, e in enumerate(y_mayo) if e == 2]\n",
    "\n",
    "transplant_deceased_indexes = transplant_indexes + deceased_indexes\n",
    "\n",
    "print(len(alive_indexes))\n",
    "print(len(transplant_indexes))\n",
    "print(len(deceased_indexes))\n",
    "print(len(transplant_deceased_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T15:03:12.658406Z",
     "start_time": "2021-04-03T15:03:12.654746Z"
    }
   },
   "outputs": [],
   "source": [
    "y_mayo = np.array(\n",
    "    [1 if i in transplant_deceased_indexes else 0 for i, e in enumerate(y_mayo)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T15:03:13.066414Z",
     "start_time": "2021-04-03T15:03:13.061727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154\n",
      "158\n"
     ]
    }
   ],
   "source": [
    "# Counts for treatment\n",
    "control_indexes_mayo = [i for i, e in enumerate(w_mayo) if e == 0]\n",
    "treatment_indexes_mayo = [i for i, e in enumerate(w_mayo) if e == 1]\n",
    "\n",
    "print(len(control_indexes_mayo))\n",
    "print(len(treatment_indexes_mayo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T15:03:13.329629Z",
     "start_time": "2021-04-03T15:03:13.326160Z"
    }
   },
   "outputs": [],
   "source": [
    "X_control_mayo = X_mayo[control_indexes_mayo]\n",
    "y_control_mayo = y_mayo[control_indexes_mayo]\n",
    "w_control_mayo = w_mayo[control_indexes_mayo]\n",
    "\n",
    "X_treatment_mayo = X_mayo[treatment_indexes_mayo]\n",
    "y_treatment_mayo = y_mayo[treatment_indexes_mayo]\n",
    "w_treatment_mayo = w_mayo[treatment_indexes_mayo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T15:03:13.570381Z",
     "start_time": "2021-04-03T15:03:13.565843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Old Covariates shape  : (154, 22)\n",
      "    Old responses shape   : (154,)\n",
      "    Old treatments shape  : (154,)\n",
      "    New covariates shape  : (158, 22)\n",
      "    New responses shape   : (158,)\n",
      "    New treatments shape  : (158,)\n",
      "    Matched sample length :  158\n",
      "                        \n"
     ]
    }
   ],
   "source": [
    "# Over-sampling of control\n",
    "X_os_mayo, y_os_mayo, w_os_mayo = utils.over_sample(\n",
    "    X_1=X_control_mayo,\n",
    "    y_1=y_control_mayo,\n",
    "    w_1=w_control_mayo,\n",
    "    sample_2_size=len(X_treatment_mayo),\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T15:03:13.808145Z",
     "start_time": "2021-04-03T15:03:13.803549Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((316, 22), (316,), (316,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_split_mayo = np.append(X_os_mayo, X_treatment_mayo, axis=0)\n",
    "y_split_mayo = np.append(y_os_mayo, y_treatment_mayo, axis=0)\n",
    "w_split_mayo = np.append(w_os_mayo, w_treatment_mayo, axis=0)\n",
    "\n",
    "X_split_mayo.shape, y_split_mayo.shape, w_split_mayo.shape  # Should all be equal in the first dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T15:03:14.209765Z",
     "start_time": "2021-04-03T15:03:14.203139Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((220, 22), (96, 22), (220,), (96,), (220,), (96,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    X_train_mayo,\n",
    "    X_test_mayo,\n",
    "    y_train_mayo,\n",
    "    y_test_mayo,\n",
    "    w_train_mayo,\n",
    "    w_test_mayo,\n",
    ") = utils.train_test_split(\n",
    "    X_split_mayo,\n",
    "    y_split_mayo,\n",
    "    w_split_mayo,\n",
    "    percent_train=0.7,\n",
    "    random_state=42,\n",
    "    maintain_proportions=True,\n",
    ")\n",
    "\n",
    "X_train_mayo.shape, X_test_mayo.shape, y_train_mayo.shape, y_test_mayo.shape, w_train_mayo.shape, w_test_mayo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMF Microfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T15:04:32.372965Z",
     "start_time": "2021-04-03T15:04:32.370083Z"
    }
   },
   "outputs": [],
   "source": [
    "X_cmf = data_cmf_micro[\"features\"]\n",
    "\n",
    "y_cmf = data_cmf_micro[\"response_biz_index\"]  # response_biz_index or response_women_emp\n",
    "\n",
    "w_cmf = data_cmf_micro[\"treatment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T15:04:33.315543Z",
     "start_time": "2021-04-03T15:04:33.309638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2576\n",
      "2752\n"
     ]
    }
   ],
   "source": [
    "# Counts for treatment\n",
    "control_indexes = [i for i, e in enumerate(w_cmf) if e == 0]\n",
    "treatment_indexes = [i for i, e in enumerate(w_cmf) if e == 1]\n",
    "\n",
    "print(len(control_indexes))\n",
    "print(len(treatment_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T15:04:34.282983Z",
     "start_time": "2021-04-03T15:04:34.277121Z"
    }
   },
   "outputs": [],
   "source": [
    "X_control_cmf = X_cmf[control_indexes]\n",
    "y_control_cmf = y_cmf[control_indexes]\n",
    "w_control_cmf = w_cmf[control_indexes]\n",
    "\n",
    "X_treatment_cmf = X_cmf[treatment_indexes]\n",
    "y_treatment_cmf = y_cmf[treatment_indexes]\n",
    "w_treatment_cmf = w_cmf[treatment_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T15:04:35.109823Z",
     "start_time": "2021-04-03T15:04:35.104615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Old Covariates shape  : (2576, 160)\n",
      "    Old responses shape   : (2576,)\n",
      "    Old treatments shape  : (2576,)\n",
      "    New covariates shape  : (2752, 160)\n",
      "    New responses shape   : (2752,)\n",
      "    New treatments shape  : (2752,)\n",
      "    Matched sample length :  2752\n",
      "                        \n"
     ]
    }
   ],
   "source": [
    "# Over-sampling of control\n",
    "X_os_cmf, y_os_cmf, w_os_cmf = utils.over_sample(\n",
    "    X_1=X_control_cmf,\n",
    "    y_1=y_control_cmf,\n",
    "    w_1=w_control_cmf,\n",
    "    sample_2_size=len(X_treatment_cmf),\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T15:04:35.727251Z",
     "start_time": "2021-04-03T15:04:35.721341Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5504, 160), (5504,), (5504,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_split_cmf = np.append(X_os_cmf, X_treatment_cmf, axis=0)\n",
    "y_split_cmf = np.append(y_os_cmf, y_treatment_cmf, axis=0)\n",
    "w_split_cmf = np.append(w_os_cmf, w_treatment_cmf, axis=0)\n",
    "\n",
    "X_split_cmf.shape, y_split_cmf.shape, w_split_cmf.shape  # Should all be equal in the first dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T15:04:36.376282Z",
     "start_time": "2021-04-03T15:04:36.229260Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3852, 160), (1652, 160), (3852,), (1652,), (3852,), (1652,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    X_train_cmf,\n",
    "    X_test_cmf,\n",
    "    y_train_cmf,\n",
    "    y_test_cmf,\n",
    "    w_train_cmf,\n",
    "    w_test_cmf,\n",
    ") = utils.train_test_split(\n",
    "    X_split_cmf,\n",
    "    y_split_cmf,\n",
    "    w_split_cmf,\n",
    "    percent_train=0.7,\n",
    "    random_state=42,\n",
    "    maintain_proportions=True,\n",
    ")\n",
    "\n",
    "X_train_cmf.shape, X_test_cmf.shape, y_train_cmf.shape, y_test_cmf.shape, w_train_cmf.shape, w_test_cmf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T15:04:40.986772Z",
     "start_time": "2021-04-03T15:04:40.982386Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_keys = {\n",
    "    \"Hillstrom\": {\n",
    "        \"X_train\": X_train_hillstrom,\n",
    "        \"y_train\": y_train_hillstrom,\n",
    "        \"w_train\": w_train_hillstrom,\n",
    "        \"X_test\": X_test_hillstrom,\n",
    "        \"y_test\": y_test_hillstrom,\n",
    "        \"w_test\": w_test_hillstrom,\n",
    "    },\n",
    "    \"Mayo PBC\": {\n",
    "        \"X_train\": X_train_mayo,\n",
    "        \"y_train\": y_train_mayo,\n",
    "        \"w_train\": w_train_mayo,\n",
    "        \"X_test\": X_test_mayo,\n",
    "        \"y_test\": y_test_mayo,\n",
    "        \"w_test\": w_test_mayo,\n",
    "    },\n",
    "    \"CMF Microfinance\": {\n",
    "        \"X_train\": X_train_cmf,\n",
    "        \"y_train\": y_train_cmf,\n",
    "        \"w_train\": w_train_cmf,\n",
    "        \"X_test\": X_test_cmf,\n",
    "        \"y_test\": y_test_cmf,\n",
    "        \"w_test\": w_test_cmf,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T01:23:10.224554Z",
     "start_time": "2020-01-27T01:23:10.221896Z"
    }
   },
   "source": [
    "Scikit-Learn models to use:\n",
    "\n",
    "- RandomForestClassifier() for Hillstrom and Mayo PBC\n",
    "- RandomForestRegressor() for CMF Microfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T15:04:51.189693Z",
     "start_time": "2021-04-03T15:04:51.184913Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Hillstrom': {}, 'Mayo PBC': {}, 'CMF Microfinance': {}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 200\n",
    "model_eval_dict = {}\n",
    "model_eval_dict[\"Hillstrom\"] = {}\n",
    "model_eval_dict[\"Mayo PBC\"] = {}\n",
    "model_eval_dict[\"CMF Microfinance\"] = {}\n",
    "model_eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T20:36:03.655755Z",
     "start_time": "2021-04-03T17:29:31.692562Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Hillstrom Iterations---\n",
      "---Mayo PBC Iterations---\n",
      "---CMF Microfinance Iterations---\n"
     ]
    }
   ],
   "source": [
    "for dataset in dataset_keys.keys():\n",
    "    if dataset in [\"Hillstrom\", \"Mayo PBC\"]:  # predict_proba\n",
    "        tm_class = TwoModel(\n",
    "            treatment_model=RandomForestClassifier(\n",
    "                n_estimators=200, criterion=\"gini\", bootstrap=True\n",
    "            ),\n",
    "            control_model=RandomForestClassifier(\n",
    "                n_estimators=200, criterion=\"gini\", bootstrap=True\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        it_class = InteractionTerm(\n",
    "            model=RandomForestClassifier(\n",
    "                n_estimators=200, criterion=\"gini\", bootstrap=True\n",
    "            )\n",
    "        )\n",
    "\n",
    "        bt_class = BinaryTransformation(\n",
    "            model=RandomForestClassifier(\n",
    "                n_estimators=200, criterion=\"gini\", bootstrap=True\n",
    "            ),\n",
    "            regularize=True,\n",
    "        )\n",
    "\n",
    "        qt_class = QuaternaryTransformation(\n",
    "            model=RandomForestClassifier(\n",
    "                n_estimators=200, criterion=\"gini\", bootstrap=True\n",
    "            ),\n",
    "            regularize=True,\n",
    "        )\n",
    "\n",
    "        ru_class = ReflectiveUplift(\n",
    "            model=RandomForestClassifier(\n",
    "                n_estimators=200, criterion=\"gini\", bootstrap=True\n",
    "            )\n",
    "        )\n",
    "\n",
    "        pu_class = PessimisticUplift(\n",
    "            model=RandomForestClassifier(\n",
    "                n_estimators=200, criterion=\"gini\", bootstrap=True\n",
    "            )\n",
    "        )\n",
    "        print(\"---{} Iterations---\".format(dataset))\n",
    "        for model in [tm_class, it_class, bt_class, qt_class, ru_class, pu_class]:\n",
    "            (\n",
    "                avg_preds,\n",
    "                all_preds,\n",
    "                avg_eval,\n",
    "                eval_variance,\n",
    "                eval_sd,\n",
    "                all_evals,\n",
    "            ) = iterate_model(\n",
    "                model=model,\n",
    "                X_train=dataset_keys[dataset][\"X_train\"],\n",
    "                y_train=dataset_keys[dataset][\"y_train\"],\n",
    "                w_train=dataset_keys[dataset][\"w_train\"],\n",
    "                X_test=dataset_keys[dataset][\"X_test\"],\n",
    "                y_test=dataset_keys[dataset][\"y_test\"],\n",
    "                w_test=dataset_keys[dataset][\"w_test\"],\n",
    "                tau_test=None,\n",
    "                n=n,\n",
    "                pred_type=\"predict_proba\",\n",
    "                eval_type=\"qini\",\n",
    "                normalize_eval=False,\n",
    "                verbose=False,  # Progress bar\n",
    "            )\n",
    "\n",
    "            model_eval_dict[dataset].update(\n",
    "                {\n",
    "                    str(model)\n",
    "                    .split(\".\")[-1]\n",
    "                    .split(\" \")[0]: {\n",
    "                        \"avg_preds\": avg_preds,\n",
    "                        \"all_preds\": all_preds,\n",
    "                        \"avg_eval\": avg_eval,\n",
    "                        \"eval_variance\": eval_variance,\n",
    "                        \"eval_sd\": eval_sd,\n",
    "                        \"all_evals\": all_evals,\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "\n",
    "    else:  # predict\n",
    "        tm_reg = TwoModel(\n",
    "            treatment_model=RandomForestRegressor(\n",
    "                n_estimators=200, criterion=\"mse\", bootstrap=True\n",
    "            ),\n",
    "            control_model=RandomForestRegressor(\n",
    "                n_estimators=200, criterion=\"mse\", bootstrap=True\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        it_reg = InteractionTerm(\n",
    "            model=RandomForestRegressor(\n",
    "                n_estimators=200, criterion=\"mse\", bootstrap=True\n",
    "            )\n",
    "        )\n",
    "        print(\"---{} Iterations---\".format(dataset))\n",
    "        for model in [tm_reg, it_reg]:\n",
    "            (\n",
    "                avg_preds,\n",
    "                all_preds,\n",
    "                avg_eval,\n",
    "                eval_variance,\n",
    "                eval_sd,\n",
    "                all_evals,\n",
    "            ) = iterate_model(\n",
    "                model=model,\n",
    "                X_train=dataset_keys[dataset][\"X_train\"],\n",
    "                y_train=dataset_keys[dataset][\"y_train\"],\n",
    "                w_train=dataset_keys[dataset][\"w_train\"],\n",
    "                X_test=dataset_keys[dataset][\"X_test\"],\n",
    "                y_test=dataset_keys[dataset][\"y_test\"],\n",
    "                w_test=dataset_keys[dataset][\"w_test\"],\n",
    "                tau_test=None,\n",
    "                n=n,\n",
    "                pred_type=\"predict\",\n",
    "                eval_type=\"qini\",\n",
    "                normalize_eval=False,\n",
    "                verbose=False,  # Progress bar\n",
    "            )\n",
    "\n",
    "            model_eval_dict[dataset].update(\n",
    "                {\n",
    "                    str(model)\n",
    "                    .split(\".\")[-1]\n",
    "                    .split(\" \")[0]: {\n",
    "                        \"avg_preds\": avg_preds,\n",
    "                        \"all_preds\": all_preds,\n",
    "                        \"avg_eval\": avg_eval,\n",
    "                        \"eval_variance\": eval_variance,\n",
    "                        \"eval_sd\": eval_sd,\n",
    "                        \"all_evals\": all_evals,\n",
    "                    }\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation and Variance Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T22:06:19.849467Z",
     "start_time": "2021-04-03T22:06:19.847640Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Qini (regularize=False)\n",
    "# df_model_eval = eval_table(model_eval_dict, variances=True, annotate_vars=True)\n",
    "\n",
    "# df_model_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T22:06:22.277267Z",
     "start_time": "2021-04-03T22:06:22.258893Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TwoModel</th>\n",
       "      <th>InteractionTerm</th>\n",
       "      <th>BinaryTransformation</th>\n",
       "      <th>QuaternaryTransformation</th>\n",
       "      <th>ReflectiveUplift</th>\n",
       "      <th>PessimisticUplift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hillstrom</th>\n",
       "      <td>-5.4762 ± 13.589***</td>\n",
       "      <td>-5.047 ± 15.417***</td>\n",
       "      <td>0.5178 ± 15.7252***</td>\n",
       "      <td>0.7397 ± 14.7509***</td>\n",
       "      <td>4.4872 ± 18.5918****</td>\n",
       "      <td>-6.0052 ± 17.936****</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mayo PBC</th>\n",
       "      <td>-0.145 ± 0.29</td>\n",
       "      <td>-0.1335 ± 0.4471</td>\n",
       "      <td>0.5542 ± 0.4268</td>\n",
       "      <td>0.5315 ± 0.4424</td>\n",
       "      <td>-0.8774 ± 0.233</td>\n",
       "      <td>0.1392 ± 0.3587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMF Microfinance</th>\n",
       "      <td>18.7289 ± 5.9138**</td>\n",
       "      <td>17.0616 ± 6.6993**</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             TwoModel     InteractionTerm  \\\n",
       "Hillstrom         -5.4762 ± 13.589***  -5.047 ± 15.417***   \n",
       "Mayo PBC                -0.145 ± 0.29    -0.1335 ± 0.4471   \n",
       "CMF Microfinance   18.7289 ± 5.9138**  17.0616 ± 6.6993**   \n",
       "\n",
       "                 BinaryTransformation QuaternaryTransformation  \\\n",
       "Hillstrom         0.5178 ± 15.7252***      0.7397 ± 14.7509***   \n",
       "Mayo PBC              0.5542 ± 0.4268          0.5315 ± 0.4424   \n",
       "CMF Microfinance                  NaN                      NaN   \n",
       "\n",
       "                      ReflectiveUplift     PessimisticUplift  \n",
       "Hillstrom         4.4872 ± 18.5918****  -6.0052 ± 17.936****  \n",
       "Mayo PBC               -0.8774 ± 0.233       0.1392 ± 0.3587  \n",
       "CMF Microfinance                   NaN                   NaN  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Qini (regularize=True)\n",
    "df_model_eval = eval_table(model_eval_dict, variances=True, annotate_vars=True)\n",
    "\n",
    "df_model_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T22:06:30.864061Z",
     "start_time": "2021-04-03T22:06:30.843591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "{} &             TwoModel &     InteractionTerm & BinaryTransformation & QuaternaryTransformation &      ReflectiveUplift &     PessimisticUplift \\\\\n",
      "\\midrule\n",
      "Hillstrom        &  -5.4762 ± 13.589*** &  -5.047 ± 15.417*** &  0.5178 ± 15.7252*** &      0.7397 ± 14.7509*** &  4.4872 ± 18.5918**** &  -6.0052 ± 17.936**** \\\\\n",
      "Mayo PBC         &        -0.145 ± 0.29 &    -0.1335 ± 0.4471 &      0.5542 ± 0.4268 &          0.5315 ± 0.4424 &       -0.8774 ± 0.233 &       0.1392 ± 0.3587 \\\\\n",
      "CMF Microfinance &   18.7289 ± 5.9138** &  17.0616 ± 6.6993** &                  NaN &                      NaN &                   NaN &                   NaN \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_model_eval.to_latex())\n",
    "df_model_eval.to_latex(\"./df_model_eval.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T22:06:35.229756Z",
     "start_time": "2021-04-03T22:06:35.220289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| TwoModel            | InteractionTerm    | BinaryTransformation   | QuaternaryTransformation   | ReflectiveUplift     | PessimisticUplift    |\n",
      "|:--------------------|:-------------------|:-----------------------|:---------------------------|:---------------------|:---------------------|\n",
      "| -5.4762 ± 13.589*** | -5.047 ± 15.417*** | 0.5178 ± 15.7252***    | 0.7397 ± 14.7509***        | 4.4872 ± 18.5918**** | -6.0052 ± 17.936**** |\n",
      "| -0.145 ± 0.29       | -0.1335 ± 0.4471   | 0.5542 ± 0.4268        | 0.5315 ± 0.4424            | -0.8774 ± 0.233      | 0.1392 ± 0.3587      |\n",
      "| 18.7289 ± 5.9138**  | 17.0616 ± 6.6993** | nan                    | nan                        | nan                  | nan                  |\n"
     ]
    }
   ],
   "source": [
    "import tabulate\n",
    "\n",
    "print(\n",
    "    tabulate.tabulate(\n",
    "        tabular_data=df_model_eval.values,\n",
    "        headers=df_model_eval.columns,\n",
    "        tablefmt=\"pipe\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}