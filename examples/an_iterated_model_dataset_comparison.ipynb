{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load Data</a></span></li><li><span><a href=\"#Data-Preparation\" data-toc-modified-id=\"Data-Preparation-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data Preparation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Hillstrom\" data-toc-modified-id=\"Hillstrom-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Hillstrom</a></span></li><li><span><a href=\"#Mayo-PBC\" data-toc-modified-id=\"Mayo-PBC-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Mayo PBC</a></span></li><li><span><a href=\"#CMF-Microfinance\" data-toc-modified-id=\"CMF-Microfinance-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>CMF Microfinance</a></span></li></ul></li><li><span><a href=\"#Iterative-Modeling\" data-toc-modified-id=\"Iterative-Modeling-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Iterative Modeling</a></span></li><li><span><a href=\"#Evaluation-and-Variance-Table\" data-toc-modified-id=\"Evaluation-and-Variance-Table-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Evaluation and Variance Table</a></span></li><li><span><a href=\"#Summary\" data-toc-modified-id=\"Summary-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Summary</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T20:35:37.469129Z",
     "start_time": "2020-02-02T20:35:37.460314Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:99% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "from causeinfer.data import hillstrom, mayo_pbc, cmf_micro\n",
    "from causeinfer.utils import plot_unit_distributions, train_test_split\n",
    "from causeinfer.utils import over_sample, mutli_cross_tab\n",
    "from causeinfer.standard_algorithms import TwoModel, InteractionTerm\n",
    "from causeinfer.standard_algorithms import BinaryTransformation\n",
    "from causeinfer.standard_algorithms import QuaternaryTransformation\n",
    "from causeinfer.evaluation import qini_score, auuc_score\n",
    "from causeinfer.evaluation import plot_cum_effect, plot_cum_gain, plot_qini\n",
    "from causeinfer.evaluation import plot_batch_responses, signal_to_noise\n",
    "from causeinfer.evaluation import iterate_model, eval_table\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 16)\n",
    "pd.set_option('display.max_columns', None)\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:99% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T20:31:39.881507Z",
     "start_time": "2020-02-02T20:31:39.877350Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/andrewmcallister/Documents/learning/programming/causeinfer/examples'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T20:31:40.415615Z",
     "start_time": "2020-02-02T20:31:40.411534Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset already exists at /Users/andrewmcallister/Documents/learning/programming/causeinfer/examples/datasets/hillstrom.csv\n",
      "The dataset already exists at /Users/andrewmcallister/Documents/learning/programming/causeinfer/examples/datasets/mayo_pbc.text\n"
     ]
    }
   ],
   "source": [
    "hillstrom.download_hillstrom()\n",
    "mayo_pbc.download_mayo_pbc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T20:31:41.945876Z",
     "start_time": "2020-02-02T20:31:40.923301Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewmcallister/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:964: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "data_hillstrom = hillstrom.load_hillstrom(user_file_path=\"datasets/hillstrom.csv\",\n",
    "                                          format_covariates=True, \n",
    "                                          normalize=True)\n",
    "data_mayo_pbc = mayo_pbc.load_mayo_pbc(user_file_path=\"datasets/mayo_pbc.text\",\n",
    "                                       format_covariates=True, \n",
    "                                       normalize=True)\n",
    "data_cmf_micro = cmf_micro.load_cmf_micro(user_file_path=\"datasets/cmf_micro\",\n",
    "                                          format_covariates=True, \n",
    "                                          normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hillstrom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T20:31:43.832562Z",
     "start_time": "2020-02-02T20:31:43.829213Z"
    }
   },
   "outputs": [],
   "source": [
    "# Covariates, treatments and responses are loaded separately\n",
    "X_hillstrom = data_hillstrom[\"features\"]\n",
    "\n",
    "y_hillstrom = data_hillstrom[\"response_visit\"] # response_visit, response_spend or response_conversion\n",
    "\n",
    "# 1 is men's campaign, 2 is women's, and 0 is control\n",
    "w_hillstrom = data_hillstrom[\"treatment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T20:31:44.300648Z",
     "start_time": "2020-02-02T20:31:44.235126Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21306\n",
      "21307\n",
      "21387\n",
      "42694\n"
     ]
    }
   ],
   "source": [
    "# Counts for treatment\n",
    "control_indexes_hillstrom = [i for i, e in enumerate(w_hillstrom) if e == 0]\n",
    "mens_indexes = [i for i, e in enumerate(w_hillstrom) if e == 1]\n",
    "womens_indexes = [i for i, e in enumerate(w_hillstrom) if e == 2]\n",
    "\n",
    "womens_mens_indexes = womens_indexes + mens_indexes\n",
    "\n",
    "print(len(control_indexes_hillstrom))\n",
    "print(len(mens_indexes))\n",
    "print(len(womens_indexes))\n",
    "print(len(womens_mens_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T20:31:44.662718Z",
     "start_time": "2020-02-02T20:31:44.644806Z"
    }
   },
   "outputs": [],
   "source": [
    "X_control_hillstrom = X_hillstrom[control_indexes_hillstrom]\n",
    "y_control_hillstrom = y_hillstrom[control_indexes_hillstrom]\n",
    "w_control_hillstrom = w_hillstrom[control_indexes_hillstrom]\n",
    "\n",
    "X_women = X_hillstrom[womens_indexes]\n",
    "y_women = y_hillstrom[womens_indexes]\n",
    "w_women = w_hillstrom[womens_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T20:31:44.960177Z",
     "start_time": "2020-02-02T20:31:44.949112Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change 2s to 1s in women's campaign\n",
    "w_women = [1 for i in w_women if i == 2]\n",
    "w_women[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T20:31:45.256567Z",
     "start_time": "2020-02-02T20:31:45.228536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Old Covariates shape  : (21306, 18)\n",
      "    Old responses shape   : (21306,)\n",
      "    Old treatments shape  : (21306,)\n",
      "    New covariates shape  : (21387, 18)\n",
      "    New responses shape   : (21387,)\n",
      "    New treatments shape  : (21387,)\n",
      "    Matched sample length :  21387\n",
      "                        \n"
     ]
    }
   ],
   "source": [
    "# Over-sampling of control\n",
    "X_os_hillstrom, y_os_hillstrom, w_os_hillstrom = over_sample(X_1=X_control_hillstrom, y_1=y_control_hillstrom, w_1=w_control_hillstrom, \n",
    "                                                             sample_2_size=len(X_women), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T20:31:45.491182Z",
     "start_time": "2020-02-02T20:31:45.483040Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42774, 18), (42774,), (42774,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_split_hillstrom = np.append(X_os_hillstrom, X_women, axis=0)\n",
    "y_split_hillstrom = np.append(y_os_hillstrom, y_women, axis=0)\n",
    "w_split_hillstrom = np.append(w_os_hillstrom, w_women, axis=0)\n",
    "\n",
    "X_split_hillstrom.shape, y_split_hillstrom.shape, w_split_hillstrom.shape # Should all be equal in the first dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T20:31:52.682382Z",
     "start_time": "2020-02-02T20:31:45.744001Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29940, 18), (12834, 18), (29940,), (12834,), (29940,), (12834,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_hillstrom, X_test_hillstrom, \\\n",
    "y_train_hillstrom, y_test_hillstrom, \\\n",
    "w_train_hillstrom, w_test_hillstrom = train_test_split(X_split_hillstrom, y_split_hillstrom, w_split_hillstrom, \n",
    "                                                       percent_train=0.7, random_state=42, \n",
    "                                                       maintain_proportions=True)\n",
    "X_train_hillstrom.shape, X_test_hillstrom.shape, \\\n",
    "y_train_hillstrom.shape, y_test_hillstrom.shape, \\\n",
    "w_train_hillstrom.shape, w_test_hillstrom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T20:31:52.689472Z",
     "start_time": "2020-02-02T20:31:52.684295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0 14970]\n",
      " [    1 14970]]\n",
      "[[   0 6417]\n",
      " [   1 6417]]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(np.unique(w_train_hillstrom, return_counts=True)).T)\n",
    "print(np.array(np.unique(w_test_hillstrom, return_counts=True)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mayo PBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T20:31:52.693832Z",
     "start_time": "2020-02-02T20:31:52.691436Z"
    }
   },
   "outputs": [],
   "source": [
    "# Covariates, treatments and responses are loaded separately\n",
    "X_mayo = data_mayo_pbc[\"features\"]\n",
    "\n",
    "# 0 is the patient is alive, 1 is a liver transplant, 2 is deceased\n",
    "y_mayo = data_mayo_pbc[\"response\"]\n",
    "\n",
    "w_mayo = data_mayo_pbc[\"treatment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T20:31:52.700847Z",
     "start_time": "2020-02-02T20:31:52.695803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\n",
      "19\n",
      "125\n",
      "144\n"
     ]
    }
   ],
   "source": [
    "# Counts for response\n",
    "alive_indexes = [i for i, e in enumerate(y_mayo) if e == 0]\n",
    "transplant_indexes = [i for i, e in enumerate(y_mayo) if e == 1]\n",
    "deceased_indexes = [i for i, e in enumerate(y_mayo) if e == 2]\n",
    "\n",
    "transplant_deceased_indexes = transplant_indexes + deceased_indexes\n",
    "\n",
    "print(len(alive_indexes))\n",
    "print(len(transplant_indexes))\n",
    "print(len(deceased_indexes))\n",
    "print(len(transplant_deceased_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T20:31:52.705910Z",
     "start_time": "2020-02-02T20:31:52.702800Z"
    }
   },
   "outputs": [],
   "source": [
    "y_mayo = np.array([1 if i in transplant_deceased_indexes else 0 for i, e in enumerate(y_mayo)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T20:31:52.711657Z",
     "start_time": "2020-02-02T20:31:52.707394Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154\n",
      "158\n"
     ]
    }
   ],
   "source": [
    "# Counts for treatment\n",
    "control_indexes_mayo = [i for i, e in enumerate(w_mayo) if e == 0]\n",
    "treatment_indexes_mayo = [i for i, e in enumerate(w_mayo) if e == 1]\n",
    "\n",
    "print(len(control_indexes_mayo))\n",
    "print(len(treatment_indexes_mayo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T20:31:52.717948Z",
     "start_time": "2020-02-02T20:31:52.714167Z"
    }
   },
   "outputs": [],
   "source": [
    "X_control_mayo = X_mayo[control_indexes_mayo]\n",
    "y_control_mayo = y_mayo[control_indexes_mayo]\n",
    "w_control_mayo = w_mayo[control_indexes_mayo]\n",
    "\n",
    "X_treatment_mayo = X_mayo[treatment_indexes_mayo]\n",
    "y_treatment_mayo = y_mayo[treatment_indexes_mayo]\n",
    "w_treatment_mayo = w_mayo[treatment_indexes_mayo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T20:31:52.723834Z",
     "start_time": "2020-02-02T20:31:52.720645Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Old Covariates shape  : (154, 22)\n",
      "    Old responses shape   : (154,)\n",
      "    Old treatments shape  : (154,)\n",
      "    New covariates shape  : (158, 22)\n",
      "    New responses shape   : (158,)\n",
      "    New treatments shape  : (158,)\n",
      "    Matched sample length :  158\n",
      "                        \n"
     ]
    }
   ],
   "source": [
    "# Over-sampling of control\n",
    "X_os_mayo, y_os_mayo, w_os_mayo = over_sample(X_1=X_control_mayo, y_1=y_control_mayo, w_1=w_control_mayo, \n",
    "                                              sample_2_size=len(X_treatment_mayo), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T20:31:52.730198Z",
     "start_time": "2020-02-02T20:31:52.725579Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((316, 22), (316,), (316,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_split_mayo = np.append(X_os_mayo, X_treatment_mayo, axis=0)\n",
    "y_split_mayo = np.append(y_os_mayo, y_treatment_mayo, axis=0)\n",
    "w_split_mayo = np.append(w_os_mayo, w_treatment_mayo, axis=0)\n",
    "\n",
    "X_split_mayo.shape, y_split_mayo.shape, w_split_mayo.shape # Should all be equal in the first dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T20:31:52.737989Z",
     "start_time": "2020-02-02T20:31:52.731821Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((220, 22), (96, 22), (220,), (96,), (220,), (96,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mayo, X_test_mayo, \\\n",
    "y_train_mayo, y_test_mayo, \\\n",
    "w_train_mayo, w_test_mayo = train_test_split(X_split_mayo, y_split_mayo, w_split_mayo, \n",
    "                                             percent_train=0.7, random_state=42, \n",
    "                                             maintain_proportions=True)\n",
    "\n",
    "X_train_mayo.shape, X_test_mayo.shape, \\\n",
    "y_train_mayo.shape, y_test_mayo.shape, \\\n",
    "w_train_mayo.shape, w_test_mayo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMF Microfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T20:31:53.540462Z",
     "start_time": "2020-02-02T20:31:53.537182Z"
    }
   },
   "outputs": [],
   "source": [
    "X_cmf = data_cmf_micro[\"features\"]\n",
    "\n",
    "y_cmf = data_cmf_micro[\"response_biz_index\"] # response_biz_index or response_women_emp\n",
    "\n",
    "w_cmf = data_cmf_micro[\"treatment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T20:31:53.787835Z",
     "start_time": "2020-02-02T20:31:53.778386Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2576\n",
      "2752\n"
     ]
    }
   ],
   "source": [
    "# Counts for treatment\n",
    "control_indexes = [i for i, e in enumerate(w_cmf) if e == 0]\n",
    "treatment_indexes = [i for i, e in enumerate(w_cmf) if e == 1]\n",
    "\n",
    "print(len(control_indexes))\n",
    "print(len(treatment_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T20:31:54.065072Z",
     "start_time": "2020-02-02T20:31:54.054941Z"
    }
   },
   "outputs": [],
   "source": [
    "X_control_cmf = X_cmf[control_indexes]\n",
    "y_control_cmf = y_cmf[control_indexes]\n",
    "w_control_cmf = w_cmf[control_indexes]\n",
    "\n",
    "X_treatment_cmf = X_cmf[treatment_indexes]\n",
    "y_treatment_cmf = y_cmf[treatment_indexes]\n",
    "w_treatment_cmf = w_cmf[treatment_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T20:31:54.301612Z",
     "start_time": "2020-02-02T20:31:54.294647Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Old Covariates shape  : (2576, 160)\n",
      "    Old responses shape   : (2576,)\n",
      "    Old treatments shape  : (2576,)\n",
      "    New covariates shape  : (2752, 160)\n",
      "    New responses shape   : (2752,)\n",
      "    New treatments shape  : (2752,)\n",
      "    Matched sample length :  2752\n",
      "                        \n"
     ]
    }
   ],
   "source": [
    "# Over-sampling of control\n",
    "X_os_cmf, y_os_cmf, w_os_cmf = over_sample(X_1=X_control_cmf, y_1=y_control_cmf, w_1=w_control_cmf, \n",
    "                               sample_2_size=len(X_treatment_cmf), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T20:31:54.554335Z",
     "start_time": "2020-02-02T20:31:54.545149Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5504, 160), (5504,), (5504,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_split_cmf = np.append(X_os_cmf, X_treatment_cmf, axis=0)\n",
    "y_split_cmf = np.append(y_os_cmf, y_treatment_cmf, axis=0)\n",
    "w_split_cmf = np.append(w_os_cmf, w_treatment_cmf, axis=0)\n",
    "\n",
    "X_split_cmf.shape, y_split_cmf.shape, w_split_cmf.shape # Should all be equal in the first dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T20:31:55.165220Z",
     "start_time": "2020-02-02T20:31:55.007877Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3852, 160), (1652, 160), (3852,), (1652,), (3852,), (1652,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cmf, X_test_cmf, \\\n",
    "y_train_cmf, y_test_cmf, \\\n",
    "w_train_cmf, w_test_cmf = train_test_split(X_split_cmf, y_split_cmf, w_split_cmf, \n",
    "                                           percent_train=0.7, random_state=42, \n",
    "                                           maintain_proportions=True)\n",
    "\n",
    "X_train_cmf.shape, X_test_cmf.shape, \\\n",
    "y_train_cmf.shape, y_test_cmf.shape, \\\n",
    "w_train_cmf.shape, w_test_cmf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T20:31:55.597260Z",
     "start_time": "2020-02-02T20:31:55.592633Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_keys = {'Hillstrom': {'X_train': X_train_hillstrom,\n",
    "                              'y_train': y_train_hillstrom,\n",
    "                              'w_train': w_train_hillstrom,\n",
    "                              'X_test': X_test_hillstrom,\n",
    "                              'y_test': y_test_hillstrom,\n",
    "                              'w_test': w_test_hillstrom}, \n",
    "                 'Mayo PBC': {'X_train': X_train_mayo,\n",
    "                              'y_train': y_train_mayo,\n",
    "                              'w_train': w_train_mayo,\n",
    "                              'X_test': X_test_mayo,\n",
    "                              'y_test': y_test_mayo,\n",
    "                              'w_test': w_test_mayo}, \n",
    "                 'CMF Microfinance': {'X_train': X_train_cmf,\n",
    "                                      'y_train': y_train_cmf,\n",
    "                                      'w_train': w_train_cmf,\n",
    "                                      'X_test': X_test_cmf,\n",
    "                                      'y_test': y_test_cmf,\n",
    "                                      'w_test': w_test_cmf}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T01:23:10.224554Z",
     "start_time": "2020-01-27T01:23:10.221896Z"
    }
   },
   "source": [
    "Scikit-Learn models to use:\n",
    "\n",
    "- RandomForestClassifier() for Hillstrom and Mayo PBC\n",
    "- RandomForestRegressor() for CMF Microfinance\n",
    "- Num trees is N for the dataset in accordance with Wager, et al 14 calculated for convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T20:35:48.425619Z",
     "start_time": "2020-02-02T20:35:48.420967Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Hillstrom': {}, 'Mayo PBC': {}, 'CMF Microfinance': {}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=10\n",
    "model_eval_dict = {}\n",
    "model_eval_dict['Hillstrom'] = {}\n",
    "model_eval_dict['Mayo PBC'] = {}\n",
    "model_eval_dict['CMF Microfinance'] = {}\n",
    "model_eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T20:47:37.927259Z",
     "start_time": "2020-02-02T20:40:57.428137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Hillstrom Iterations---\n",
      "Starting TwoModel iterations\n",
      "10.0 percent of iterations have finished\n",
      "20.0 percent of iterations have finished\n",
      "30.0 percent of iterations have finished\n",
      "40.0 percent of iterations have finished\n",
      "50.0 percent of iterations have finished\n",
      "60.0 percent of iterations have finished\n",
      "70.0 percent of iterations have finished\n",
      "80.0 percent of iterations have finished\n",
      "90.0 percent of iterations have finished\n",
      "100.0 percent of iterations have finished\n",
      "-----\n",
      "Starting InteractionTerm iterations\n",
      "10.0 percent of iterations have finished\n",
      "20.0 percent of iterations have finished\n",
      "30.0 percent of iterations have finished\n",
      "40.0 percent of iterations have finished\n",
      "50.0 percent of iterations have finished\n",
      "60.0 percent of iterations have finished\n",
      "70.0 percent of iterations have finished\n",
      "80.0 percent of iterations have finished\n",
      "90.0 percent of iterations have finished\n",
      "100.0 percent of iterations have finished\n",
      "-----\n",
      "Starting BinaryTransformation iterations\n",
      "10.0 percent of iterations have finished\n",
      "20.0 percent of iterations have finished\n",
      "30.0 percent of iterations have finished\n",
      "40.0 percent of iterations have finished\n",
      "50.0 percent of iterations have finished\n",
      "60.0 percent of iterations have finished\n",
      "70.0 percent of iterations have finished\n",
      "80.0 percent of iterations have finished\n",
      "90.0 percent of iterations have finished\n",
      "100.0 percent of iterations have finished\n",
      "-----\n",
      "Starting QuaternaryTransformation iterations\n",
      "10.0 percent of iterations have finished\n",
      "20.0 percent of iterations have finished\n",
      "30.0 percent of iterations have finished\n",
      "40.0 percent of iterations have finished\n",
      "50.0 percent of iterations have finished\n",
      "60.0 percent of iterations have finished\n",
      "70.0 percent of iterations have finished\n",
      "80.0 percent of iterations have finished\n",
      "90.0 percent of iterations have finished\n",
      "100.0 percent of iterations have finished\n",
      "-----\n",
      "---Mayo PBC Iterations---\n",
      "Starting TwoModel iterations\n",
      "10.0 percent of iterations have finished\n",
      "20.0 percent of iterations have finished\n",
      "30.0 percent of iterations have finished\n",
      "40.0 percent of iterations have finished\n",
      "50.0 percent of iterations have finished\n",
      "60.0 percent of iterations have finished\n",
      "70.0 percent of iterations have finished\n",
      "80.0 percent of iterations have finished\n",
      "90.0 percent of iterations have finished\n",
      "100.0 percent of iterations have finished\n",
      "-----\n",
      "Starting InteractionTerm iterations\n",
      "10.0 percent of iterations have finished\n",
      "20.0 percent of iterations have finished\n",
      "30.0 percent of iterations have finished\n",
      "40.0 percent of iterations have finished\n",
      "50.0 percent of iterations have finished\n",
      "60.0 percent of iterations have finished\n",
      "70.0 percent of iterations have finished\n",
      "80.0 percent of iterations have finished\n",
      "90.0 percent of iterations have finished\n",
      "100.0 percent of iterations have finished\n",
      "-----\n",
      "Starting BinaryTransformation iterations\n",
      "10.0 percent of iterations have finished\n",
      "20.0 percent of iterations have finished\n",
      "30.0 percent of iterations have finished\n",
      "40.0 percent of iterations have finished\n",
      "50.0 percent of iterations have finished\n",
      "60.0 percent of iterations have finished\n",
      "70.0 percent of iterations have finished\n",
      "80.0 percent of iterations have finished\n",
      "90.0 percent of iterations have finished\n",
      "100.0 percent of iterations have finished\n",
      "-----\n",
      "Starting QuaternaryTransformation iterations\n",
      "10.0 percent of iterations have finished\n",
      "20.0 percent of iterations have finished\n",
      "30.0 percent of iterations have finished\n",
      "40.0 percent of iterations have finished\n",
      "50.0 percent of iterations have finished\n",
      "60.0 percent of iterations have finished\n",
      "70.0 percent of iterations have finished\n",
      "80.0 percent of iterations have finished\n",
      "90.0 percent of iterations have finished\n",
      "100.0 percent of iterations have finished\n",
      "-----\n",
      "---CMF Microfinance Iterations---\n",
      "Starting TwoModel iterations\n",
      "10.0 percent of iterations have finished\n",
      "20.0 percent of iterations have finished\n",
      "30.0 percent of iterations have finished\n",
      "40.0 percent of iterations have finished\n",
      "50.0 percent of iterations have finished\n",
      "60.0 percent of iterations have finished\n",
      "70.0 percent of iterations have finished\n",
      "80.0 percent of iterations have finished\n",
      "90.0 percent of iterations have finished\n",
      "100.0 percent of iterations have finished\n",
      "-----\n",
      "Starting InteractionTerm iterations\n",
      "10.0 percent of iterations have finished\n",
      "20.0 percent of iterations have finished\n",
      "30.0 percent of iterations have finished\n",
      "40.0 percent of iterations have finished\n",
      "50.0 percent of iterations have finished\n",
      "60.0 percent of iterations have finished\n",
      "70.0 percent of iterations have finished\n",
      "80.0 percent of iterations have finished\n",
      "90.0 percent of iterations have finished\n",
      "100.0 percent of iterations have finished\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "for dataset in dataset_keys.keys():\n",
    "    num_trees = dataset_keys[dataset]['X_train'].shape[0] + dataset_keys[dataset]['X_test'].shape[0]\n",
    "    if dataset in ['Hillstrom', 'Mayo PBC']:\n",
    "        base_classifier_model = RandomForestClassifier(n_estimators=200, # num_trees \n",
    "                                                       criterion='gini', \n",
    "                                                       bootstrap=True)\n",
    "        \n",
    "        tm_class = TwoModel(treatment_model=base_classifier_model,\n",
    "                            control_model=base_classifier_model)\n",
    "        it_class = InteractionTerm(model=base_classifier_model)\n",
    "        bt_class = BinaryTransformation(model=base_classifier_model, regularize=False)\n",
    "        qt_class = QuaternaryTransformation(model=base_classifier_model, regularize=False)\n",
    "        print('---{} Iterations---'.format(dataset))\n",
    "        for model in [tm_class, it_class, bt_class, qt_class]:\n",
    "            avg_preds, all_preds, \\\n",
    "            avg_eval, eval_variance, \\\n",
    "            eval_sd, all_evals = iterate_model(model=model, \n",
    "                                               X_train=dataset_keys[dataset]['X_train'], \n",
    "                                               y_train=dataset_keys[dataset]['y_train'], \n",
    "                                               w_train=dataset_keys[dataset]['w_train'],\n",
    "                                               X_test=dataset_keys[dataset]['X_test'], \n",
    "                                               y_test=dataset_keys[dataset]['y_test'], \n",
    "                                               w_test=dataset_keys[dataset]['w_test'], \n",
    "                                               tau_test=None, n=n,\n",
    "                                               pred_type='predict_proba', eval_type='qini',\n",
    "                                               normalize_eval=False, notify_iter=int(n/10))\n",
    "            \n",
    "            model_eval_dict[dataset].update({str(model).split('.')[-1].split(' ')[0]: {'avg_preds': avg_preds, 'all_preds': all_preds, \n",
    "                                                                                       'avg_eval': avg_eval, 'eval_variance': eval_variance,\n",
    "                                                                                       'eval_sd': eval_sd, 'all_evals': all_evals}})\n",
    "        \n",
    "    else:\n",
    "        base_regression_model = RandomForestRegressor(n_estimators=200, # num_trees\n",
    "                                                      criterion='mse', \n",
    "                                                      bootstrap=True)\n",
    "\n",
    "        tm_reg = TwoModel(treatment_model=base_regression_model,\n",
    "                          control_model=base_regression_model)\n",
    "        it_reg = InteractionTerm(model=base_regression_model)\n",
    "        print('---{} Iterations---'.format(dataset))\n",
    "        for model in [tm_reg, it_reg]:\n",
    "            avg_preds, all_preds, \\\n",
    "            avg_eval, eval_variance, \\\n",
    "            eval_sd, all_evals = iterate_model(model=model, \n",
    "                                               X_train=dataset_keys[dataset]['X_train'], \n",
    "                                               y_train=dataset_keys[dataset]['y_train'], \n",
    "                                               w_train=dataset_keys[dataset]['w_train'],\n",
    "                                               X_test=dataset_keys[dataset]['X_test'], \n",
    "                                               y_test=dataset_keys[dataset]['y_test'], \n",
    "                                               w_test=dataset_keys[dataset]['w_test'], \n",
    "                                               tau_test=None, n=n,\n",
    "                                               pred_type='predict', eval_type='qini',\n",
    "                                               normalize_eval=False, notify_iter=int(n/10))\n",
    "            \n",
    "            model_eval_dict[dataset].update({str(model).split('.')[-1].split(' ')[0]: {'avg_preds': avg_preds, 'all_preds': all_preds, \n",
    "                                                                                       'avg_eval': avg_eval, 'eval_variance': eval_variance,\n",
    "                                                                                       'eval_sd': eval_sd, 'all_evals': all_evals}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation and Variance Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T20:47:40.995962Z",
     "start_time": "2020-02-02T20:47:40.982104Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'BinaryTransformation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-8e6f5ccb29cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Qini\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_model_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_eval_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotate_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_model_eval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/causeinfer/evaluation.py\u001b[0m in \u001b[0;36meval_table\u001b[0;34m(eval_dict, variances, annotate_vars)\u001b[0m\n\u001b[1;32m   1233\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                 \u001b[0meval_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg_eval'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'BinaryTransformation'"
     ]
    }
   ],
   "source": [
    "# Qini\n",
    "df_model_eval = eval_table(model_eval_dict, variances=False, annotate_vars=False)\n",
    "\n",
    "df_model_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
