{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load Data</a></span></li><li><span><a href=\"#Data-Preparation\" data-toc-modified-id=\"Data-Preparation-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data Preparation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Hillstrom\" data-toc-modified-id=\"Hillstrom-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Hillstrom</a></span></li><li><span><a href=\"#Mayo-PBC\" data-toc-modified-id=\"Mayo-PBC-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Mayo PBC</a></span></li><li><span><a href=\"#CMF-Microfinance\" data-toc-modified-id=\"CMF-Microfinance-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>CMF Microfinance</a></span></li></ul></li><li><span><a href=\"#Iterative-Modeling\" data-toc-modified-id=\"Iterative-Modeling-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Iterative Modeling</a></span></li><li><span><a href=\"#Evaluation-Table\" data-toc-modified-id=\"Evaluation-Table-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Evaluation Table</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from causeinfer.data import hillstrom, mayo_pbc, cmf_micro\n",
    "from causeinfer.utilities import plot_unit_distributions, train_test_split\n",
    "from causeinfer.utilities import over_sample, mutli_cross_tab\n",
    "from causeinfer.standard_algorithms import TwoModel, InteractionTerm\n",
    "from causeinfer.standard_algorithms import BinaryClassTransformation\n",
    "from causeinfer.standard_algorithms import QuaternaryClassTransformation\n",
    "from causeinfer.evaluation import qini_score, auuc_score\n",
    "from causeinfer.evaluation import plot_cum_effect, plot_cum_gain, plot_qini\n",
    "from causeinfer.evaluation import plot_batch_responses, signal_to_noise\n",
    "from causeinfer.evaluation import iterate_model, eval_table\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 16)\n",
    "pd.set_option('display.max_columns', None)\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:99% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T02:27:57.959793Z",
     "start_time": "2020-01-25T02:27:57.956609Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset already exists at /Users/andrewmcallister/Documents/learning/programming/causeinfer/examples/datasets/hillstrom.csv\n",
      "The dataset already exists at /Users/andrewmcallister/Documents/learning/programming/causeinfer/examples/datasets/mayo_pbc.text\n"
     ]
    }
   ],
   "source": [
    "hillstrom.download_hillstrom()\n",
    "mayo_pbc.download_mayo_pbc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hillstrom = hillstrom.load_hillstrom(user_file_path=\"datasets/hillstrom.csv\",\n",
    "                                          format_covariates=True, \n",
    "                                          normalize=True)\n",
    "data_mayo_pbc = mayo_pbc.load_mayo_pbc(user_file_path=\"datasets/mayo_pbc.text\",\n",
    "                                       format_covariates=True, \n",
    "                                       normalize=True)\n",
    "data_cmf_micro = cmf_micro.load_cmf_micro(user_file_path=\"datasets/cmf_micro\",\n",
    "                                          format_covariates=True, \n",
    "                                          normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hillstrom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covariates, treatments and responses are loaded separately\n",
    "X_hillstrom = data_hillstrom[\"features\"]\n",
    "\n",
    "y_hillstrom = data_hillstrom[\"response_visit\"] # response_visit, response_spend or response_conversion\n",
    "\n",
    "# 1 is men's campaign, 2 is women's, and 0 is control\n",
    "w_hillstrom = data_hillstrom[\"treatment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts for treatment\n",
    "control_indexes = [i for i, e in enumerate(w) if e == 0]\n",
    "mens_indexes = [i for i, e in enumerate(w) if e == 1]\n",
    "womens_indexes = [i for i, e in enumerate(w) if e == 2]\n",
    "\n",
    "womens_mens_indexes = womens_indexes + mens_indexes\n",
    "\n",
    "print(len(control_indexes))\n",
    "print(len(mens_indexes))\n",
    "print(len(womens_indexes))\n",
    "print(len(womens_mens_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_control_hillstrom = X_hillstrom[control_indexes]\n",
    "y_control_hillstrom = y_hillstrom[control_indexes]\n",
    "w_control_hillstrom = w_hillstrom[control_indexes]\n",
    "\n",
    "X_women = X_hillstrom[womens_indexes]\n",
    "y_women = y_hillstrom[womens_indexes]\n",
    "w_women = w_hillstrom[womens_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change 2s to 1s in women's campaign\n",
    "w_women = [1 for i in w_women if i == 2]\n",
    "w_women[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over-sampling of control\n",
    "X_os_hillstrom, y_os_hillstrom, w_os_hillstrom = over_sample(X_1=X_control_hillstrom, y_1=y_control_hillstrom, w_1=w_control_hillstrom, \n",
    "                                                             sample_2_size=len(X_women), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_split_hillstrom = np.append(X_os_hillstrom, X_women, axis=0)\n",
    "y_split_hillstrom = np.append(y_os_hillstrom, y_women, axis=0)\n",
    "w_split_hillstrom = np.append(w_os_hillstrom, w_women, axis=0)\n",
    "\n",
    "X_split_hillstrom.shape, y_split_hillstrom.shape, w_split_hillstrom.shape # Should all be equal in the first dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_hillstrom, X_test_hillstrom, \\\n",
    "y_train_hillstrom, y_test_hillstrom, \\\n",
    "w_train_hillstrom, w_test_hillstrom = train_test_split(X_split_hillstrom, y_split_hillstrom, w_split_hillstrom, \n",
    "                                                       percent_train=0.7, random_state=42, \n",
    "                                                       maintain_proportions=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mayo PBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covariates, treatments and responses are loaded separately\n",
    "X_mayo = data_mayo_pbc[\"features\"]\n",
    "\n",
    "# 0 is the patient is alive, 1 is a liver transplant, 2 is deceased\n",
    "y_mayo = data_mayo_pbc[\"response\"]\n",
    "\n",
    "w_mayo = data_mayo_pbc[\"treatment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts for response\n",
    "alive_indexes = [i for i, e in enumerate(y) if e == 0]\n",
    "transplant_indexes = [i for i, e in enumerate(y) if e == 1]\n",
    "deceased_indexes = [i for i, e in enumerate(y) if e == 2]\n",
    "\n",
    "transplant_deceased_indexes = transplant_indexes + deceased_indexes\n",
    "\n",
    "print(len(alive_indexes))\n",
    "print(len(transplant_indexes))\n",
    "print(len(deceased_indexes))\n",
    "print(len(transplant_deceased_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts for treatment\n",
    "control_indexes = [i for i, e in enumerate(w) if e == 0]\n",
    "treatment_indexes = [i for i, e in enumerate(w) if e == 1]\n",
    "\n",
    "print(len(control_indexes))\n",
    "print(len(treatment_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_control_mayo = X_mayo[control_indexes]\n",
    "y_control_mayo = y_mayo[control_indexes]\n",
    "w_control_mayo = w_mayo[control_indexes]\n",
    "\n",
    "X_treatment_mayo = X_mayo[treatment_indexes]\n",
    "y_treatment_mayo = y_mayo[treatment_indexes]\n",
    "w_treatment_mayo = w_mayo[treatment_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over-sampling of control\n",
    "X_os_mayo, y_os_mayo, w_os_mayo = over_sample(X_1=X_control_mayo, y_1=y_control_mayo, w_1=w_control_mayo, \n",
    "                                              sample_2_size=len(X_treatment_mayo), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_split_mayo = np.append(X_os_mayo, X_treatment_mayo, axis=0)\n",
    "y_split_mayo = np.append(y_os_mayo, y_treatment_mayo, axis=0)\n",
    "w_split_mayo = np.append(w_os_mayo, w_treatment_mayo, axis=0)\n",
    "\n",
    "X_split.shape, y_split.shape, w_split.shape # Should all be equal in the first dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mayo, X_test_mayo, \\\n",
    "y_train_mayo, y_test_mayo, \\\n",
    "w_train_mayo, w_test_mayo = train_test_split(X_split_mayo, y_split_mayo, w_split_mayo, \n",
    "                                             percent_train=0.7, random_state=42, \n",
    "                                             maintain_proportions=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMF Microfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cmf = data_cmf_micro[\"features\"]\n",
    "\n",
    "y_cmf = data_cmf_micro[\"response_biz_index\"] # response_biz_index or response_women_emp\n",
    "\n",
    "w_cmf = data_cmf_micro[\"treatment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts for treatment\n",
    "control_indexes = [i for i, e in enumerate(w_cmf) if e == 0]\n",
    "treatment_indexes = [i for i, e in enumerate(w_cmf) if e == 1]\n",
    "\n",
    "print(len(control_indexes))\n",
    "print(len(treatment_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_control_cmf = X_cmf[control_indexes]\n",
    "y_control_cmf = y_cmf[control_indexes]\n",
    "w_control_cmf = w_cmf[control_indexes]\n",
    "\n",
    "X_treatment_cmf = X_cmf[treatment_indexes]\n",
    "y_treatment_cmf = y_cmf[treatment_indexes]\n",
    "w_treatment_cmf = w_cmf[treatment_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over-sampling of control\n",
    "X_os_cmf, y_os_cmf, w_os_cmf = over_sample(X_1=X_control_cmf, y_1=y_control_cmf, w_1=w_control_cmf, \n",
    "                               sample_2_size=len(X_treatment_cmf), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_split_cmf = np.append(X_os_cmf, X_treatment_cmf, axis=0)\n",
    "y_split_cmf = np.append(y_os_cmf, y_treatment_cmf, axis=0)\n",
    "w_split_cmf = np.append(w_os_cmf, w_treatment_cmf, axis=0)\n",
    "\n",
    "X_split_cmf.shape, y_split_cmf.shape, w_split_cmf.shape # Should all be equal in the first dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cmf, X_test_cmf, \\\n",
    "y_train_cmf, y_test_cmf, \\\n",
    "w_train_cmf, w_test_cmf = train_test_split(X_split_cmf, y_split_cmf, w_split_cmf, \n",
    "                                           percent_train=0.7, random_state=42, \n",
    "                                           maintain_proportions=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_keys = {'Hillstrom': {'pred_type': 'predict_proba',\n",
    "                               'X_train': X_train_hillstrom,\n",
    "                               'y_train': y_train_hillstrom,\n",
    "                               'w_train': w_train_hillstrom,\n",
    "                               'X_test': X_test_hillstrom,\n",
    "                               'y_test': y_test_hillstrom,\n",
    "                               'w_test': w_test_hillstrom}, \n",
    "                 'Mayo PBC': {'pred_type': 'predict_proba',\n",
    "                               'X_train': X_train_mayo,\n",
    "                               'y_train': y_train_mayo,\n",
    "                               'w_train': w_train_mayo,\n",
    "                               'X_test': X_test_mayo,\n",
    "                               'y_test': y_test_mayo,\n",
    "                               'w_test': w_test_mayo}, \n",
    "                 'CMF Microfinance': {'pred_type': 'predict',\n",
    "                               'X_train': X_train_cmf,\n",
    "                               'y_train': y_train_cmf,\n",
    "                               'w_train': w_train_cmf,\n",
    "                               'X_test': X_test_cmf,\n",
    "                               'y_test': y_test_cmf,\n",
    "                               'w_test': w_test_cmf}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_base_model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = TwoModel(treatment_model=sklearn_base_model,\n",
    "              control_model=sklearn_base_model)\n",
    "it = InteractionTerm(model=sklearn_base_model)\n",
    "bct = BinaryClassTransformation(model=sklearn_base_model)\n",
    "qct = QuaternaryClassTransformation(model=sklearn_base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format so that a two level dictionary is being filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T22:51:47.949559Z",
     "start_time": "2020-01-25T22:51:47.946856Z"
    }
   },
   "outputs": [],
   "source": [
    "two_level_dict['2'] = {'2': 'Another second level str'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T22:51:48.627699Z",
     "start_time": "2020-01-25T22:51:48.624452Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': {'2': 'Second level term'}, '2': {'2': 'Another second level str'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_level_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_key in dataset_keys.keys():\n",
    "    if data_key in ['Hillstrom', 'Mayo PBC']:\n",
    "        for model in [tm, it, bct, qct]:\n",
    "            print('Starting {} iterations:'.format(str(model).split('.')[-1].split(' ')[0]))\n",
    "            avg_preds, all_preds, \\\n",
    "            avg_eval, eval_variance, \\\n",
    "            eval_sd, all_evals = iterate_model(model=model, X_train=X_train, y_train=y_train, w_train=w_train,\n",
    "                                                X_test=X_test, y_test=y_test, w_test=w_test, tau_test=None, n=n,\n",
    "                                                pred_type='predict_proba', eval_type='qini', \n",
    "                                                normalize_eval=False, notify_iter=int(n/10))\n",
    "            model_eval_dict['{}'.format(data_key)] = {str(model).split('.')[-1].split(' ')[0]: = [avg_preds, all_preds, \n",
    "                                                                                                  avg_eval, eval_variance,\n",
    "                                                                                                  eval_sd, all_evals]}\n",
    "            print('-----')\n",
    "        \n",
    "    else:\n",
    "        for model in [tm, it]:\n",
    "            print('Starting {} iterations:'.format(str(model).split('.')[-1].split(' ')[0]))\n",
    "            avg_preds, all_preds, \\\n",
    "            avg_eval, eval_variance, \\\n",
    "            eval_sd, all_evals = iterate_model(model=model, X_train=X_train, y_train=y_train, w_train=w_train,\n",
    "                                                X_test=X_test, y_test=y_test, w_test=w_test, tau_test=None, n=n,\n",
    "                                                pred_type='predict', eval_type='qini', \n",
    "                                                normalize_eval=False, notify_iter=int(n/10))\n",
    "            model_eval_dict['{}'.format(data_key)] = {str(model).split('.')[-1].split(' ')[0]: = [avg_preds, all_preds, \n",
    "                                                                                                  avg_eval, eval_variance,\n",
    "                                                                                                  eval_sd, all_evals]}\n",
    "            print('-----')     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_models = list(model_eval_dict.keys())\n",
    "iter_evals = [i[2] for i in model_eval_dict.values()]\n",
    "iter_vars = [i[3] for i in model_eval_dict.values()]\n",
    "iter_sds = [i[4] for i in model_eval_dict.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_eval = eval_table(models=iter_models, datasets='Hillstrom', \n",
    "                           evals=iter_evals, variances=iter_vars, \n",
    "                           sds=iter_sds, annotate=True)\n",
    "df_model_eval"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
